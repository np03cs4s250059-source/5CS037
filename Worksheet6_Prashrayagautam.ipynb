{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SagyaGhimire/5CS037/blob/main/Worksheet6_SagyaGhimire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "cLec3tKqtGH_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIGMOID FUNCTION"
      ],
      "metadata": {
        "id": "f88deB_2dHbZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iU_Xqy_Ckosr"
      },
      "outputs": [],
      "source": [
        "def logistic_function(x):\n",
        "    y = 1 / (1 + np.exp(-x))\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "  x_scalar = 0\n",
        "  expected_output_scalar = round(1 / (1 + np.exp(0)), 3) # Expected output: 0.5\n",
        "  assert round(logistic_function(x_scalar), 3) == expected_output_scalar, \"Test failed for scalar input\"\n",
        "  # Test with positive scalar input\n",
        "  x_pos = 2\n",
        "  expected_output_pos = round(1 / (1 + np.exp(-2)), 3) # Expected output: ~0.881\n",
        "  assert round(logistic_function(x_pos), 3) == expected_output_pos, \"Test failed for positive scalar input\"\n",
        "  # Test with negative scalar input\n",
        "  x_neg = -3\n",
        "  expected_output_neg = round(1 / (1 + np.exp(3)), 3) # Expected output: ~0.047\n",
        "  assert round(logistic_function(x_neg), 3) == expected_output_neg, \"Test failed for negative scalar input\"\n",
        "  # Test with numpy array input\n",
        "  x_array = np.array([0, 2, -3])\n",
        "  expected_output_array = np.array([0.5, 0.881, 0.047]) # Adjusted expected values rounded to 3 decimals\n",
        "  # Use np.round to round the array element-wise and compare\n",
        "  assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array), \"Test failed for numpy array input\"\n",
        "  print(\"All tests passed!\")\n",
        "  # Run the test case\n",
        "  test_logistic_function()"
      ],
      "metadata": {
        "id": "pzUCVUTds8_3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOG LOSS"
      ],
      "metadata": {
        "id": "m4sIMge9dE47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "    # Ensure y_pred is clipped to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "    loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "MgubRFXbuaHa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function:\n",
        "y_true, y_pred = 0, 0.1\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')\n",
        "print(\"+++++++++++++--------------------------++++++++++++++++++++++++\")\n",
        "y_true, y_pred = 1, 0.9\n",
        "print(f'log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_SmS34ZuthV",
        "outputId": "0c3e494c-89eb-4123-fc0c-107fd8454e51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log loss(0, 0.1) ==> 0.10536051565782628\n",
            "+++++++++++++--------------------------++++++++++++++++++++++++\n",
            "log loss(1, 0.9) ==> 0.10536051565782628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_log_loss():\n",
        "  # Test case 1: Perfect prediction (y_true = 1, y_pred = 1)\n",
        "  y_true = 1\n",
        "  y_pred = 1\n",
        "  expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=1, y_pred=1)\"\n",
        "  # Test case 2: Perfect prediction (y_true = 0, y_pred = 0)\n",
        "  y_true = 0\n",
        "  y_pred = 0\n",
        "  expected_loss = 0.0 # Log loss is 0 for perfect prediction\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for perfect prediction (y_true=0, y_pred=0)\"\n",
        "  # Test case 3: Incorrect prediction (y_true = 1, y_pred = 0)\n",
        "  y_true = 1\n",
        "  y_pred = 0\n",
        "  try:\n",
        "    log_loss(y_true, y_pred)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "  # Test case 4: Incorrect prediction (y_true = 0, y_pred = 1)\n",
        "  y_true = 0\n",
        "  y_pred = 1\n",
        "  try:\n",
        "    # Similar to above, clipping prevents ValueError.\n",
        "    log_loss(y_true, y_pred)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "  # Test case 5: Partially correct prediction\n",
        "  y_true = 1\n",
        "  y_pred = 0.8\n",
        "  expected_loss = -(1 * np.log(0.8)) - (0 * np.log(0.2)) # ~0.2231\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss), \"Test failed for partially correct prediction\"\n",
        "  print(\"All tests passed!\")\n",
        "\n",
        "# Run the test case\n",
        "test_log_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPLPTZxDu0Z8",
        "outputId": "bac0d323-b793-4eb6-805b-69462f00d7ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION OF COST FUNCTION"
      ],
      "metadata": {
        "id": "o_9jNt_kdTIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred), \"Length of true values and length of predicted values do not match\"\n",
        "    n = len(y_true)\n",
        "    loss_vec = log_loss(y_true, y_pred)\n",
        "    cost = np.sum(loss_vec) / n\n",
        "    return cost"
      ],
      "metadata": {
        "id": "VlxbSbMceZfS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_cost_function():\n",
        "    # Test case 1: Simple example with known expected cost\n",
        "    y_true = np.array([1, 0, 1])\n",
        "    y_pred = np.array([0.9, 0.1, 0.8])\n",
        "    # Expected output: Manually calculate cost for these values\n",
        "    # log_loss(y_true, y_pred) for each example\n",
        "    expected_cost = (-(1 * np.log(0.9)) - (1 - 1) * np.log(1 - 0.9) +\n",
        "    -(0 * np.log(0.1)) - (1 - 0) * np.log(1 - 0.1) +\n",
        "    -(1 * np.log(0.8)) - (1 - 1) * np.log(1 - 0.8)) / 3\n",
        "\n",
        "    # Call the cost_function to get the result\n",
        "    result = cost_function(y_true, y_pred)\n",
        "    # Assert that the result is close to the expected cost with a tolerance of 1e-6\n",
        "    assert np.isclose(result, expected_cost, atol=1e-6), f\"Test failed: {result} != {expected_cost}\"\n",
        "    print(\"Test passed for simple case!\")\n",
        "\n",
        "# Run the test case\n",
        "test_cost_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv_mI6Cpel05",
        "outputId": "0cd62ff3-ea7c-49f9-dcd2-cfbea9bff34a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed for simple case!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementation of cost function for sigmoid function"
      ],
      "metadata": {
        "id": "kzd7YtpZe7YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute cost function in terms of model parameters - using vectorization\n",
        "def costfunction_logreg(X, y, w, b):\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, \"Number of feature observations and number of target observations do not match.\"\n",
        "    assert len(w) == d, \"Number of features and number of weight parameters do not match.\"\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "    cost = cost_function(y, y_pred)\n",
        "    return cost\n",
        "\n",
        "# Testing the Function:\n",
        "X, y, w, b = np.array([[10, 20], [-10, 10]]), np.array([1, 0]), np.array([0.5, 1.5]), 1\n",
        "print(f\"cost for logistic regression(X = {X}, y = {y}, w = {w}, b = {b}) = {costfunction_logreg(X, y, w, b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8-6vWKjetGP",
        "outputId": "0a7fb33d-7b7c-4f00-b6f6-2bfcfad37026"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for logistic regression(X = [[ 10  20]\n",
            " [-10  10]], y = [1 0], w = [0.5 1.5], b = 1) = 5.500008350834906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing Gradients for Sigmoid Regression"
      ],
      "metadata": {
        "id": "LpQWQtpgf0sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, y, w, b):\n",
        "    n = X.shape[0]\n",
        "\n",
        "    y_pred = logistic_function(np.dot(X, w) + b)   # Your Code Here\n",
        "\n",
        "    grad_w = (1/n) * np.dot(X.T, (y_pred - y))     # Your Code Here\n",
        "    grad_b = (1/n) * np.sum(y_pred - y)            # Your Code Here\n",
        "\n",
        "    return grad_w, grad_b"
      ],
      "metadata": {
        "id": "Y-TNi2pLfUrl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing it"
      ],
      "metadata": {
        "id": "gU7dCXePgTSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test case\n",
        "X = np.array([[10, 20], [-10, 10]]) # shape (2, 2)\n",
        "y = np.array([1, 0]) # shape (2,)\n",
        "w = np.array([0.5, 1.5]) # shape (2,)\n",
        "b = 1 # scalar\n",
        "# Assertion tests\n",
        "try:\n",
        "  grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "  print(\"Gradients computed successfully.\")\n",
        "  print(f\"grad_w: {grad_w}\")\n",
        "  print(f\"grad_b: {grad_b}\")\n",
        "except AssertionError as e:\n",
        "  print(f\"Assertion error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7RZK47CgHYA",
        "outputId": "fe2f0af7-d999-4969-e6b6-a750f9fc0335"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n",
            "grad_w: [-4.99991649  4.99991649]\n",
            "grad_b: 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent for Sigmoid Regression:"
      ],
      "metadata": {
        "id": "rnzYGplUgY4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "    cost_history = []\n",
        "    params_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        # Compute gradients\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        # Compute cost\n",
        "        cost = costfunction_logreg(X, y, w, b)\n",
        "\n",
        "        cost_history.append(cost)\n",
        "        params_history.append((w.copy(), b))\n",
        "\n",
        "    return w, b, cost_history, params_history\n"
      ],
      "metadata": {
        "id": "dbO9YHhWiKO6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gradient_descent():\n",
        "    X = np.array([[0.1, 0.2], [-0.1, 0.1]]) # Shape (2, 2)\n",
        "    y = np.array([1, 0]) # Shape (2,)\n",
        "    w = np.zeros(X.shape[1]) # Shape (2,)\n",
        "    b = 0.0 # Scalar\n",
        "    alpha = 0.1\n",
        "    n_iter = 100\n",
        "# Run gradient descent\n",
        "    w_out, b_out, cost_history, _ = gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False,\n",
        "show_params=False)\n",
        "# Assertions\n",
        "    assert len(cost_history) == n_iter, \"Cost history length does not match the number of iterations\"\n",
        "    assert w_out.shape == w.shape, \"Shape of output weights does not match the initial weights\"\n",
        "    assert isinstance(b_out, float), \"Bias output is not a float\"\n",
        "    assert cost_history[-1] < cost_history[0], \"Cost did not decrease over iterations\"\n",
        "    print(\"All tests passed!\")\n",
        "# Run the test\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scqnv_ZzhDMP",
        "outputId": "f0fa9770-cbda-4789-8b95-191c6b3e9ce6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision/Prediction Function:"
      ],
      "metadata": {
        "id": "ujARArJgihR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w, b, threshold=0.5):\n",
        "  z=np.dot(X,w)+b\n",
        "  y_test_prob =logistic_function(z)\n",
        "  y_pred = np.where(y_test_prob >= threshold, 1, 0)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "LqQ7in3jhpfb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A simple assertion test for Prediction Function:\n",
        "def test_prediction():\n",
        "    X_test = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]]) # Shape (3, 2)\n",
        "    w_test = np.array([1.0, -1.0]) # Shape (2,)\n",
        "    b_test = 0.0 # Scalar bias\n",
        "    threshold = 0.5 # Default threshold\n",
        "# Updated expected output\n",
        "    expected_output = np.array([0, 1, 1])\n",
        "# Call the prediction function\n",
        "    y_pred = prediction(X_test, w_test, b_test, threshold)\n",
        "# Assert that the output matches the expected output\n",
        "    assert np.array_equal(y_pred, expected_output), f\"Expected {expected_output}, but got {y_pred}\"\n",
        "    print(\"Test passed!\")\n",
        "test_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBCq2ku4i9OI",
        "outputId": "c6ea3843-dbe7-43a4-be05-d665d7c6c5f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of the Classifier"
      ],
      "metadata": {
        "id": "LH9bO7FbjIBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(y_true, y_pred):\n",
        "#Computes confusion matrix, precision, recall, and F1-score\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))   # Your Code Here\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))   # Your Code Here\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))   # Your Code Here\n",
        "\n",
        "    confusion_matrix = np.array([[TN, FP],\n",
        "                                 [FN, TP]])\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0        # Your Code Here\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # Your Code Here\n",
        "\n",
        "    return confusion_matrix, precision, recall, f1_score\n"
      ],
      "metadata": {
        "id": "-Ikxt7tTjDNO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNdND_LhpBSb"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}